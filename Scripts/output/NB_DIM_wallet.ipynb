{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f84101c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [9]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb9ffe73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:34:42.267319Z",
     "iopub.status.busy": "2024-12-27T15:34:42.267110Z",
     "iopub.status.idle": "2024-12-27T15:34:44.219373Z",
     "shell.execute_reply": "2024-12-27T15:34:44.216873Z"
    },
    "papermill": {
     "duration": 2.036237,
     "end_time": "2024-12-27T15:34:44.284665",
     "exception": false,
     "start_time": "2024-12-27T15:34:42.248428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.utils import *\n",
    "from delta import *\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490e53de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:34:44.346268Z",
     "iopub.status.busy": "2024-12-27T15:34:44.345526Z",
     "iopub.status.idle": "2024-12-27T15:35:44.715675Z",
     "shell.execute_reply": "2024-12-27T15:35:44.711179Z"
    },
    "papermill": {
     "duration": 60.51837,
     "end_time": "2024-12-27T15:35:44.837152",
     "exception": false,
     "start_time": "2024-12-27T15:34:44.318782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://95bc4b79fafa:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NB_DIM_Wallet</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff6f9168d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"NB_DIM_Wallet\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "# Spark will automatically use the master specified in spark-defaults.conf\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfb43f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:35:44.869399Z",
     "iopub.status.busy": "2024-12-27T15:35:44.861004Z",
     "iopub.status.idle": "2024-12-27T15:35:44.885696Z",
     "shell.execute_reply": "2024-12-27T15:35:44.885153Z"
    },
    "papermill": {
     "duration": 0.042627,
     "end_time": "2024-12-27T15:35:44.889003",
     "exception": false,
     "start_time": "2024-12-27T15:35:44.846376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trgt_path_processed = \"/mnt/Wallet/Wallet_Parquet\"\n",
    "trgt_path_csv = \"/mnt/Wallet/Wallet_Processed\"\n",
    "source_path = \"/data/Project_Files/Template.xlsm\"\n",
    "sheet_name ='SPENDING_HISTORY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1acf37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:35:44.899331Z",
     "iopub.status.busy": "2024-12-27T15:35:44.899150Z",
     "iopub.status.idle": "2024-12-27T15:35:48.312585Z",
     "shell.execute_reply": "2024-12-27T15:35:48.310468Z"
    },
    "papermill": {
     "duration": 3.427364,
     "end_time": "2024-12-27T15:35:48.322059",
     "exception": false,
     "start_time": "2024-12-27T15:35:44.894695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the Excel file (use Spark-Excel library)\n",
    "df = pd.read_excel(source_path, sheet_name = sheet_name)\n",
    "df = spark.createDataFrame(df)\n",
    "df= df.withColumn(\"Date\", to_date(df[\"Date\"],\"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2320bad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:35:48.346274Z",
     "iopub.status.busy": "2024-12-27T15:35:48.345996Z",
     "iopub.status.idle": "2024-12-27T15:35:56.519777Z",
     "shell.execute_reply": "2024-12-27T15:35:56.494272Z"
    },
    "papermill": {
     "duration": 8.206781,
     "end_time": "2024-12-27T15:35:56.547011",
     "exception": false,
     "start_time": "2024-12-27T15:35:48.340230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select distinct `Wallet used` from vw_src\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         Wallet used|\n",
      "+--------------------+\n",
      "|               G-pay|\n",
      "|       Amazon Wallet|\n",
      "|           ICICI Pay|\n",
      "|Credit Card - Amazon|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"vw_src\")\n",
    "query = \"select distinct `Wallet used` from vw_src\"\n",
    "print(query)\n",
    "df_src = spark.sql(query)\n",
    "df_src.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc32fb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:35:56.584145Z",
     "iopub.status.busy": "2024-12-27T15:35:56.583213Z",
     "iopub.status.idle": "2024-12-27T15:35:56.641804Z",
     "shell.execute_reply": "2024-12-27T15:35:56.640908Z"
    },
    "papermill": {
     "duration": 0.075326,
     "end_time": "2024-12-27T15:35:56.644038",
     "exception": false,
     "start_time": "2024-12-27T15:35:56.568712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_output = \\\n",
    "df_src.withColumn(\"Walletsk\",xxhash64(\"Wallet used\")).withColumnRenamed(\"Wallet used\",\"WalletUsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "639a7542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:35:56.657789Z",
     "iopub.status.busy": "2024-12-27T15:35:56.657553Z",
     "iopub.status.idle": "2024-12-27T15:35:56.710640Z",
     "shell.execute_reply": "2024-12-27T15:35:56.709847Z"
    },
    "papermill": {
     "duration": 0.063882,
     "end_time": "2024-12-27T15:35:56.713048",
     "exception": false,
     "start_time": "2024-12-27T15:35:56.649166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_output.createOrReplaceTempView(\"vw_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930140cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:35:56.721409Z",
     "iopub.status.busy": "2024-12-27T15:35:56.721049Z",
     "iopub.status.idle": "2024-12-27T15:35:56.758962Z",
     "shell.execute_reply": "2024-12-27T15:35:56.757901Z"
    },
    "papermill": {
     "duration": 0.047559,
     "end_time": "2024-12-27T15:35:56.763993",
     "exception": false,
     "start_time": "2024-12-27T15:35:56.716434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGE INTO delta.`/mnt/Wallet/Wallet_Parquet` AS target USING vw_source AS source ON target.Walletsk = source.Walletsk WHEN MATCHED THEN UPDATE SET target.WalletUsed = source.WalletUsed, target.Walletsk = source.Walletsk\n"
     ]
    }
   ],
   "source": [
    "column_name = df_output.columns\n",
    "set_clause = \", \".join([f\"target.{i} = source.{i}\" for i in column_name])\n",
    "query = f\"MERGE INTO delta.`{trgt_path_processed}` AS target USING vw_source AS source ON target.Walletsk = source.Walletsk WHEN MATCHED THEN UPDATE SET {set_clause}\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09936686",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e0ec992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T15:35:56.772181Z",
     "iopub.status.busy": "2024-12-27T15:35:56.771923Z",
     "iopub.status.idle": "2024-12-27T15:37:02.824896Z",
     "shell.execute_reply": "2024-12-27T15:37:02.816656Z"
    },
    "papermill": {
     "duration": 66.267026,
     "end_time": "2024-12-27T15:37:03.034543",
     "exception": true,
     "start_time": "2024-12-27T15:35:56.767517",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 51060)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o33.sql",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DeltaTable\u001b[38;5;241m.\u001b[39misDeltaTable(spark, trgt_path_processed):\n\u001b[1;32m      2\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMERGE INTO delta.`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrgt_path_processed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` AS target USING vw_source AS source ON target.Walletsk = source.Walletsk WHEN MATCHED THEN UPDATE SET \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_clause\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m      5\u001b[0m     query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE TABLE delta.`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrgt_path_processed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` USING DELTA AS SELECT * FROM vw_source\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o33.sql"
     ]
    }
   ],
   "source": [
    "if DeltaTable.isDeltaTable(spark, trgt_path_processed):\n",
    "    query = f\"MERGE INTO delta.`{trgt_path_processed}` AS target USING vw_source AS source ON target.Walletsk = source.Walletsk WHEN MATCHED THEN UPDATE SET {set_clause}\"\n",
    "    spark.sql(query)\n",
    "else :\n",
    "    query=f\"CREATE TABLE delta.`{trgt_path_processed}` USING DELTA AS SELECT * FROM vw_source\"\n",
    "    spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99d2d5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "spark.read.format(\"delta\").load(trgt_path_processed).coalesce(1).write.format(\"csv\").option(\"header\",\"true\").mode(\"overwrite\").save(trgt_path_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 145.665178,
   "end_time": "2024-12-27T15:37:06.113844",
   "environment_variables": {},
   "exception": true,
   "input_path": "/home/jovyan/Notebooks/NB_DIM_wallet.ipynb",
   "output_path": "/home/jovyan/Notebooks/output/NB_DIM_wallet.ipynb",
   "parameters": {},
   "start_time": "2024-12-27T15:34:40.448666",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}