[2024-12-24T10:26:14.691+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-12-24T10:26:14.703+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_Calendar_NTBK.NB_Notebook_job manual__2024-12-24T10:26:12.304689+00:00 [queued]>
[2024-12-24T10:26:14.715+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_Calendar_NTBK.NB_Notebook_job manual__2024-12-24T10:26:12.304689+00:00 [queued]>
[2024-12-24T10:26:14.717+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2024-12-24T10:26:14.727+0000] {taskinstance.py:2889} INFO - Executing <Task(DockerOperator): NB_Notebook_job> on 2024-12-24 10:26:12.304689+00:00
[2024-12-24T10:26:14.734+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=994) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-12-24T10:26:14.734+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'dag_Calendar_NTBK', 'NB_Notebook_job', 'manual__2024-12-24T10:26:12.304689+00:00', '--job-id', '426', '--raw', '--subdir', 'DAGS_FOLDER/dag_calendar.py', '--cfg-path', '/tmp/tmpnlzkzror']
[2024-12-24T10:26:14.736+0000] {standard_task_runner.py:72} INFO - Started process 997 to run task
[2024-12-24T10:26:14.736+0000] {standard_task_runner.py:105} INFO - Job 426: Subtask NB_Notebook_job
[2024-12-24T10:26:14.781+0000] {task_command.py:467} INFO - Running <TaskInstance: dag_Calendar_NTBK.NB_Notebook_job manual__2024-12-24T10:26:12.304689+00:00 [running]> on host ca7403376fcd
[2024-12-24T10:26:14.843+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_Calendar_NTBK' AIRFLOW_CTX_TASK_ID='NB_Notebook_job' AIRFLOW_CTX_EXECUTION_DATE='2024-12-24T10:26:12.304689+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-24T10:26:12.304689+00:00'
[2024-12-24T10:26:14.844+0000] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-24T10:26:15.246+0000] {docker.py:379} INFO - Starting docker container from image spark-cluster:version-1.0.0
[2024-12-24T10:26:17.289+0000] {docker.py:73} INFO - Input Notebook:  /home/jovyan/Notebooks/NB_Calendar.ipynb
[2024-12-24T10:26:17.302+0000] {docker.py:73} INFO - Output Notebook: /home/jovyan/Notebooks/output/NB_Calendar.ipynb
[2024-12-24T10:26:18.786+0000] {docker.py:73} INFO - Executing notebook with kernel: python3
[2024-12-24T10:26:18.789+0000] {docker.py:73} INFO - Executing Cell 1---------------------------------------
[2024-12-24T10:26:19.507+0000] {docker.py:73} INFO - Ending Cell 1------------------------------------------
[2024-12-24T10:26:19.511+0000] {docker.py:73} INFO - Executing Cell 2---------------------------------------
[2024-12-24T10:26:19.533+0000] {docker.py:73} INFO - Ending Cell 2------------------------------------------
[2024-12-24T10:26:19.537+0000] {docker.py:73} INFO - Executing Cell 3---------------------------------------
[2024-12-24T10:26:21.374+0000] {docker.py:73} INFO - :: loading settings :: url = jar:file:/usr/local/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2024-12-24T10:26:21.478+0000] {docker.py:73} INFO - Ivy Default Cache set to: /home/jovyan/.ivy2/cache
[2024-12-24T10:26:21.480+0000] {docker.py:73} INFO - The jars for the packages stored in: /home/jovyan/.ivy2/jars
[2024-12-24T10:26:21.481+0000] {docker.py:73} INFO - io.delta#delta-spark_2.12 added as a dependency
[2024-12-24T10:26:21.482+0000] {docker.py:73} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-6ea52bd5-df07-4b81-8f23-ccdfad79d1aa;1.0
[2024-12-24T10:26:21.482+0000] {docker.py:73} INFO - 	confs: [default]
[2024-12-24T10:26:22.898+0000] {docker.py:73} INFO - 	found io.delta#delta-spark_2.12;3.1.0 in central
[2024-12-24T10:26:23.309+0000] {docker.py:73} INFO - 	found io.delta#delta-storage;3.1.0 in central
[2024-12-24T10:26:26.066+0000] {docker.py:73} INFO - 	found org.antlr#antlr4-runtime;4.9.3 in central
[2024-12-24T10:26:26.266+0000] {docker.py:73} INFO - downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.1.0/delta-spark_2.12-3.1.0.jar ...
[2024-12-24T10:26:27.730+0000] {docker.py:73} INFO - 	[SUCCESSFUL ] io.delta#delta-spark_2.12;3.1.0!delta-spark_2.12.jar (1649ms)
[2024-12-24T10:26:27.915+0000] {docker.py:73} INFO - downloading https://repo1.maven.org/maven2/io/delta/delta-storage/3.1.0/delta-storage-3.1.0.jar ...
[2024-12-24T10:26:28.104+0000] {docker.py:73} INFO - 	[SUCCESSFUL ] io.delta#delta-storage;3.1.0!delta-storage.jar (371ms)
[2024-12-24T10:26:28.291+0000] {docker.py:73} INFO - downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.9.3/antlr4-runtime-4.9.3.jar ...
[2024-12-24T10:26:28.485+0000] {docker.py:73} INFO - 	[SUCCESSFUL ] org.antlr#antlr4-runtime;4.9.3!antlr4-runtime.jar (379ms)
[2024-12-24T10:26:28.486+0000] {docker.py:73} INFO - :: resolution report :: resolve 4599ms :: artifacts dl 2405ms
[2024-12-24T10:26:28.487+0000] {docker.py:73} INFO - 	:: modules in use:
[2024-12-24T10:26:28.487+0000] {docker.py:73} INFO - 	io.delta#delta-spark_2.12;3.1.0 from central in [default]
[2024-12-24T10:26:28.487+0000] {docker.py:73} INFO - 	io.delta#delta-storage;3.1.0 from central in [default]
[2024-12-24T10:26:28.488+0000] {docker.py:73} INFO - 	org.antlr#antlr4-runtime;4.9.3 from central in [default]
[2024-12-24T10:26:28.488+0000] {docker.py:73} INFO - 	---------------------------------------------------------------------
[2024-12-24T10:26:28.489+0000] {docker.py:73} INFO - 	|                  |            modules            ||   artifacts   |
[2024-12-24T10:26:28.489+0000] {docker.py:73} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2024-12-24T10:26:28.489+0000] {docker.py:73} INFO - 	---------------------------------------------------------------------
[2024-12-24T10:26:28.489+0000] {docker.py:73} INFO - 	|      default     |   3   |   3   |   3   |   0   ||   3   |   3   |
[2024-12-24T10:26:28.490+0000] {docker.py:73} INFO - 	---------------------------------------------------------------------
[2024-12-24T10:26:28.493+0000] {docker.py:73} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-6ea52bd5-df07-4b81-8f23-ccdfad79d1aa
[2024-12-24T10:26:28.494+0000] {docker.py:73} INFO - 	confs: [default]
[2024-12-24T10:26:28.515+0000] {docker.py:73} INFO - 	3 artifacts copied, 0 already retrieved (5727kB/21ms)
[2024-12-24T10:26:28.706+0000] {docker.py:73} INFO - 24/12/24 10:26:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-12-24T10:26:28.835+0000] {docker.py:73} INFO - Setting default log level to "WARN".
[2024-12-24T10:26:28.836+0000] {docker.py:73} INFO - To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[2024-12-24T10:26:29.473+0000] {docker.py:73} INFO - 24/12/24 10:26:29 WARN StandaloneSchedulerBackend: Dynamic allocation enabled without spark.executor.cores explicitly set, you may get more executors allocated than expected. It's recommended to set spark.executor.cores explicitly. Please check SPARK-30299 for more details.
[2024-12-24T10:26:29.781+0000] {docker.py:73} INFO - 24/12/24 10:26:29 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.
[2024-12-24T10:26:31.130+0000] {docker.py:73} INFO - <pyspark.sql.session.SparkSession at 0xffff53217f50>
[2024-12-24T10:26:31.141+0000] {docker.py:73} INFO - Ending Cell 3------------------------------------------
[2024-12-24T10:26:31.146+0000] {docker.py:73} INFO - Executing Cell 4---------------------------------------
[2024-12-24T10:26:31.165+0000] {docker.py:73} INFO - Ending Cell 4------------------------------------------
[2024-12-24T10:26:31.167+0000] {docker.py:73} INFO - Executing Cell 5---------------------------------------
[2024-12-24T10:26:31.178+0000] {docker.py:73} INFO - Ending Cell 5------------------------------------------
[2024-12-24T10:26:31.180+0000] {docker.py:73} INFO - Executing Cell 6---------------------------------------
[2024-12-24T10:26:33.839+0000] {docker.py:73} INFO - Ending Cell 6------------------------------------------
[2024-12-24T10:26:33.857+0000] {docker.py:73} INFO - Executing Cell 7---------------------------------------
[2024-12-24T10:26:34.071+0000] {docker.py:73} INFO - Ending Cell 7------------------------------------------
[2024-12-24T10:26:34.079+0000] {docker.py:73} INFO - Executing Cell 8---------------------------------------
[2024-12-24T10:26:34.349+0000] {docker.py:73} INFO - Ending Cell 8------------------------------------------
[2024-12-24T10:26:34.357+0000] {docker.py:73} INFO - Executing Cell 9---------------------------------------
[2024-12-24T10:26:37.015+0000] {docker.py:73} INFO - [Stage 0:>                                                          (0 + 2) / 2]
[2024-12-24T10:26:38.824+0000] {docker.py:73} INFO - 
[2024-12-24T10:26:38.848+0000] {docker.py:73} INFO - 18628
[2024-12-24T10:26:38.850+0000] {docker.py:73} INFO - Ending Cell 9------------------------------------------
[2024-12-24T10:26:38.858+0000] {docker.py:73} INFO - Executing Cell 10--------------------------------------
[2024-12-24T10:26:38.926+0000] {docker.py:73} INFO - Ending Cell 10-----------------------------------------
[2024-12-24T10:26:38.928+0000] {docker.py:73} INFO - Executing Cell 11--------------------------------------
[2024-12-24T10:26:39.035+0000] {docker.py:73} INFO - CREATE TABLE delta.`/mnt/Calendar/Calendar_Parquet/` USING DELTA AS SELECT * FROM vw_source
[2024-12-24T10:26:41.234+0000] {docker.py:73} INFO - [Stage 3:>                                                          (0 + 2) / 2]
[2024-12-24T10:26:44.260+0000] {docker.py:73} INFO - 
[2024-12-24T10:26:46.226+0000] {docker.py:73} INFO - 24/12/24 10:26:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2024-12-24T10:26:48.479+0000] {docker.py:73} INFO - [Stage 7:>                                                         (0 + 8) / 50]
[2024-12-24T10:26:49.479+0000] {docker.py:73} INFO - [Stage 7:=========>                                                (8 + 8) / 50]
[2024-12-24T10:26:49.673+0000] {docker.py:73} INFO - [Stage 7:==============>                                          (13 + 8) / 50]
[2024-12-24T10:26:49.886+0000] {docker.py:73} INFO - [Stage 7:=====================>                                   (19 + 8) / 50]
[2024-12-24T10:26:50.083+0000] {docker.py:73} INFO - [Stage 7:============================>                            (25 + 8) / 50]
[2024-12-24T10:26:50.287+0000] {docker.py:73} INFO - [Stage 7:===================================>                     (31 + 8) / 50]
[2024-12-24T10:26:50.488+0000] {docker.py:73} INFO - [Stage 7:============================================>            (39 + 8) / 50]
[2024-12-24T10:26:50.693+0000] {docker.py:73} INFO - [Stage 7:==================================================>      (44 + 6) / 50]
[2024-12-24T10:26:51.104+0000] {docker.py:73} INFO - 
[2024-12-24T10:26:51.263+0000] {docker.py:73} INFO - DataFrame[]
[2024-12-24T10:26:51.267+0000] {docker.py:73} INFO - Ending Cell 11-----------------------------------------
[2024-12-24T10:26:51.273+0000] {docker.py:73} INFO - Executing Cell 12--------------------------------------
[2024-12-24T10:26:52.527+0000] {docker.py:73} INFO - [Stage 12:===========>                                           (10 + 10) / 50]
[2024-12-24T10:26:52.709+0000] {docker.py:73} INFO - [Stage 12:=============================================>          (41 + 8) / 50]
[2024-12-24T10:26:52.794+0000] {docker.py:73} INFO - 
[2024-12-24T10:26:54.132+0000] {docker.py:73} INFO - [Stage 13:>                                                         (0 + 1) / 1]
[2024-12-24T10:26:54.349+0000] {docker.py:73} INFO - 
[2024-12-24T10:26:54.412+0000] {docker.py:73} INFO - Ending Cell 12-----------------------------------------
[2024-12-24T10:26:54.419+0000] {docker.py:73} INFO - Executing Cell 13--------------------------------------
[2024-12-24T10:26:55.952+0000] {docker.py:73} INFO - [Stage 15:>                                                    (60 + 8) / 10000]
[2024-12-24T10:26:56.136+0000] {docker.py:73} INFO - [Stage 15:>                                                    (78 + 8) / 10000]
[2024-12-24T10:26:56.348+0000] {docker.py:73} INFO - [Stage 15:>                                                   (108 + 9) / 10000]
[2024-12-24T10:26:56.568+0000] {docker.py:73} INFO - [Stage 15:>                                                   (146 + 8) / 10000]
[2024-12-24T10:26:56.751+0000] {docker.py:73} INFO - [Stage 15:>                                                   (166 + 9) / 10000]
[2024-12-24T10:26:56.951+0000] {docker.py:73} INFO - [Stage 15:=>                                                  (199 + 8) / 10000]
[2024-12-24T10:26:57.158+0000] {docker.py:73} INFO - [Stage 15:=>                                                 (245 + 12) / 10000]
[2024-12-24T10:26:57.359+0000] {docker.py:73} INFO - [Stage 15:=>                                                  (288 + 9) / 10000]
[2024-12-24T10:26:57.558+0000] {docker.py:73} INFO - [Stage 15:=>                                                 (348 + 10) / 10000]
[2024-12-24T10:26:57.755+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (404 + 8) / 10000]
[2024-12-24T10:26:57.975+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (429 + 9) / 10000]
[2024-12-24T10:26:58.169+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (452 + 8) / 10000]
[2024-12-24T10:26:58.364+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (480 + 9) / 10000]
[2024-12-24T10:26:58.569+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (508 + 8) / 10000]
[2024-12-24T10:26:58.774+0000] {docker.py:73} INFO - [Stage 15:==>                                                (538 + 12) / 10000]
[2024-12-24T10:26:58.971+0000] {docker.py:73} INFO - [Stage 15:===>                                                (577 + 8) / 10000]
[2024-12-24T10:26:59.178+0000] {docker.py:73} INFO - [Stage 15:==>                                                (586 + 14) / 10000]
[2024-12-24T10:26:59.373+0000] {docker.py:73} INFO - [Stage 15:===>                                                (621 + 8) / 10000]
[2024-12-24T10:26:59.576+0000] {docker.py:73} INFO - [Stage 15:===>                                                (650 + 8) / 10000]
[2024-12-24T10:26:59.776+0000] {docker.py:73} INFO - [Stage 15:===>                                               (694 + 11) / 10000]
[2024-12-24T10:26:59.985+0000] {docker.py:73} INFO - [Stage 15:===>                                                (754 + 8) / 10000]
[2024-12-24T10:27:00.187+0000] {docker.py:73} INFO - [Stage 15:====>                                               (785 + 8) / 10000]
[2024-12-24T10:27:00.378+0000] {docker.py:73} INFO - [Stage 15:====>                                               (819 + 8) / 10000]
[2024-12-24T10:27:00.585+0000] {docker.py:73} INFO - [Stage 15:====>                                               (856 + 8) / 10000]
[2024-12-24T10:27:00.780+0000] {docker.py:73} INFO - [Stage 15:====>                                               (886 + 8) / 10000]
[2024-12-24T10:27:00.978+0000] {docker.py:73} INFO - [Stage 15:====>                                               (957 + 8) / 10000]
[2024-12-24T10:27:01.186+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1050 + 9) / 10000]
[2024-12-24T10:27:01.390+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1148 + 8) / 10000]
[2024-12-24T10:27:01.593+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1255 + 8) / 10000]
[2024-12-24T10:27:01.793+0000] {docker.py:73} INFO - [Stage 15:======>                                           (1353 + 10) / 10000]
[2024-12-24T10:27:01.996+0000] {docker.py:73} INFO - [Stage 15:=======>                                          (1449 + 14) / 10000]
[2024-12-24T10:27:02.202+0000] {docker.py:73} INFO - [Stage 15:=======>                                           (1499 + 8) / 10000]
[2024-12-24T10:27:02.401+0000] {docker.py:73} INFO - [Stage 15:========>                                          (1575 + 9) / 10000]
[2024-12-24T10:27:02.601+0000] {docker.py:73} INFO - [Stage 15:========>                                         (1672 + 11) / 10000]
[2024-12-24T10:27:02.804+0000] {docker.py:73} INFO - [Stage 15:========>                                          (1748 + 8) / 10000]
[2024-12-24T10:27:03.005+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1772 + 8) / 10000]
[2024-12-24T10:27:03.209+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1798 + 8) / 10000]
[2024-12-24T10:27:03.410+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1809 + 9) / 10000]
[2024-12-24T10:27:03.610+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1825 + 8) / 10000]
[2024-12-24T10:27:03.814+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1857 + 8) / 10000]
[2024-12-24T10:27:04.028+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1889 + 8) / 10000]
[2024-12-24T10:27:04.231+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1909 + 8) / 10000]
[2024-12-24T10:27:04.429+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1937 + 9) / 10000]
[2024-12-24T10:27:04.634+0000] {docker.py:73} INFO - [Stage 15:=========>                                         (1956 + 9) / 10000]
[2024-12-24T10:27:04.826+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (1983 + 8) / 10000]
[2024-12-24T10:27:05.096+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2001 + 8) / 10000]
[2024-12-24T10:27:05.237+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2024 + 8) / 10000]
[2024-12-24T10:27:05.462+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2034 + 8) / 10000]
[2024-12-24T10:27:05.666+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2042 + 8) / 10000]
[2024-12-24T10:27:05.887+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2065 + 8) / 10000]
[2024-12-24T10:27:06.059+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2085 + 9) / 10000]
[2024-12-24T10:27:06.262+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2099 + 8) / 10000]
[2024-12-24T10:27:06.468+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2121 + 9) / 10000]
[2024-12-24T10:27:06.662+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2133 + 9) / 10000]
[2024-12-24T10:27:06.868+0000] {docker.py:73} INFO - [Stage 15:==========>                                        (2149 + 9) / 10000]
[2024-12-24T10:27:07.057+0000] {docker.py:73} INFO - [Stage 15:===========>                                       (2176 + 8) / 10000]
[2024-12-24T10:27:07.283+0000] {docker.py:73} INFO - [Stage 15:===========>                                       (2184 + 8) / 10000]
[2024-12-24T10:27:07.461+0000] {docker.py:73} INFO - [Stage 15:===========>                                       (2195 + 8) / 10000]
[2024-12-24T10:27:07.662+0000] {docker.py:73} INFO - [Stage 15:===========>                                       (2220 + 8) / 10000]
[2024-12-24T10:27:07.913+0000] {docker.py:73} INFO - [Stage 15:===========>                                       (2245 + 8) / 10000]
[2024-12-24T10:27:08.064+0000] {docker.py:73} INFO - [Stage 15:===========>                                       (2263 + 9) / 10000]
[2024-12-24T10:27:08.316+0000] {docker.py:73} INFO - [Stage 15:===========>                                       (2326 + 8) / 10000]
[2024-12-24T10:27:08.487+0000] {docker.py:73} INFO - [Stage 15:===========>                                       (2348 + 8) / 10000]
[2024-12-24T10:27:08.718+0000] {docker.py:73} INFO - [Stage 15:============>                                      (2377 + 8) / 10000]
[2024-12-24T10:27:08.914+0000] {docker.py:73} INFO - [Stage 15:============>                                     (2400 + 10) / 10000]
[2024-12-24T10:27:09.140+0000] {docker.py:73} INFO - [Stage 15:============>                                      (2417 + 8) / 10000]
[2024-12-24T10:27:09.283+0000] {docker.py:73} INFO - [Stage 15:============>                                      (2457 + 9) / 10000]
[2024-12-24T10:27:09.533+0000] {docker.py:73} INFO - [Stage 15:============>                                      (2509 + 9) / 10000]
[2024-12-24T10:27:09.714+0000] {docker.py:73} INFO - [Stage 15:============>                                      (2532 + 8) / 10000]
[2024-12-24T10:27:09.915+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2555 + 8) / 10000]
[2024-12-24T10:27:10.150+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2567 + 8) / 10000]
[2024-12-24T10:27:10.363+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2575 + 8) / 10000]
[2024-12-24T10:27:10.554+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2583 + 8) / 10000]
[2024-12-24T10:27:10.770+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2591 + 8) / 10000]
[2024-12-24T10:27:10.963+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2604 + 8) / 10000]
[2024-12-24T10:27:11.166+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2613 + 8) / 10000]
[2024-12-24T10:27:11.367+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2621 + 8) / 10000]
[2024-12-24T10:27:11.584+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2637 + 8) / 10000]
[2024-12-24T10:27:11.981+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2645 + 8) / 10000]
[2024-12-24T10:27:12.156+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2661 + 8) / 10000]
[2024-12-24T10:27:12.428+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2684 + 9) / 10000]
[2024-12-24T10:27:12.616+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2705 + 8) / 10000]
[2024-12-24T10:27:12.838+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2713 + 8) / 10000]
[2024-12-24T10:27:13.002+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2714 + 8) / 10000]
[2024-12-24T10:27:13.282+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2719 + 8) / 10000]
[2024-12-24T10:27:13.478+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2720 + 8) / 10000]
[2024-12-24T10:27:13.807+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2720 + 9) / 10000]
[2024-12-24T10:27:14.714+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2721 + 8) / 10000]
[2024-12-24T10:27:14.944+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2726 + 8) / 10000]
[2024-12-24T10:27:15.136+0000] {docker.py:73} INFO - 24/12/24 10:27:15 WARN TransportChannelHandler: Exception in connection from /172.19.0.5:33680
[2024-12-24T10:27:15.138+0000] {docker.py:73} INFO - java.net.SocketException: Connection reset
[2024-12-24T10:27:15.141+0000] {docker.py:73} INFO - 	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:394)
[2024-12-24T10:27:15.143+0000] {docker.py:73} INFO - 	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:426)
[2024-12-24T10:27:15.145+0000] {docker.py:73} INFO - 	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:254)
[2024-12-24T10:27:15.146+0000] {docker.py:73} INFO - 	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)
[2024-12-24T10:27:15.150+0000] {docker.py:73} INFO - 	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)
[2024-12-24T10:27:15.159+0000] {docker.py:73} INFO - 	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
[2024-12-24T10:27:15.160+0000] {docker.py:73} INFO - 	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
[2024-12-24T10:27:15.161+0000] {docker.py:73} INFO - 	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
[2024-12-24T10:27:15.164+0000] {docker.py:73} INFO - 	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
[2024-12-24T10:27:15.166+0000] {docker.py:73} INFO - 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
[2024-12-24T10:27:15.168+0000] {docker.py:73} INFO - 	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
[2024-12-24T10:27:15.173+0000] {docker.py:73} INFO - 	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2024-12-24T10:27:15.180+0000] {docker.py:73} INFO - 	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2024-12-24T10:27:15.185+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:15.620+0000] {docker.py:73} INFO - 24/12/24 10:27:15 ERROR TaskSchedulerImpl: Lost executor 0 on 172.19.0.5: Command exited with code 137
[2024-12-24T10:27:15.844+0000] {docker.py:73} INFO - 24/12/24 10:27:15 WARN TaskSetManager: Lost task 2723.0 in stage 15.0 (TID 2840) (172.19.0.5 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137
[2024-12-24T10:27:15.861+0000] {docker.py:73} INFO - 24/12/24 10:27:15 WARN TaskSetManager: Lost task 2728.0 in stage 15.0 (TID 2845) (172.19.0.5 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137
[2024-12-24T10:27:15.863+0000] {docker.py:73} INFO - 24/12/24 10:27:15 WARN TaskSetManager: Lost task 2727.0 in stage 15.0 (TID 2844) (172.19.0.5 executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Command exited with code 137
[2024-12-24T10:27:16.725+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_18 !
[2024-12-24T10:27:16.758+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_39 !
[2024-12-24T10:27:16.758+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_34 !
[2024-12-24T10:27:16.759+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_9 !
[2024-12-24T10:27:16.759+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_42 !
[2024-12-24T10:27:16.759+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_3 !
[2024-12-24T10:27:16.760+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_16 !
[2024-12-24T10:27:16.763+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_40 !
[2024-12-24T10:27:16.764+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_11 !
[2024-12-24T10:27:16.768+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_46 !
[2024-12-24T10:27:16.772+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_24 !
[2024-12-24T10:27:16.774+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_41 !
[2024-12-24T10:27:16.776+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_35 !
[2024-12-24T10:27:16.779+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_26 !
[2024-12-24T10:27:16.780+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_4 !
[2024-12-24T10:27:16.780+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_33 !
[2024-12-24T10:27:16.781+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_10 !
[2024-12-24T10:27:16.783+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_43 !
[2024-12-24T10:27:16.784+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_47 !
[2024-12-24T10:27:16.784+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_28 !
[2024-12-24T10:27:16.785+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_19 !
[2024-12-24T10:27:16.786+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_23 !
[2024-12-24T10:27:16.786+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_2 !
[2024-12-24T10:27:16.787+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_22 !
[2024-12-24T10:27:16.788+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_14 !
[2024-12-24T10:27:16.790+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_8 !
[2024-12-24T10:27:16.791+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_0 !
[2024-12-24T10:27:16.792+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_21 !
[2024-12-24T10:27:16.793+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_45 !
[2024-12-24T10:27:16.794+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_44 !
[2024-12-24T10:27:16.795+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_38 !
[2024-12-24T10:27:16.797+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_6 !
[2024-12-24T10:27:16.798+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_49 !
[2024-12-24T10:27:16.801+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_29 !
[2024-12-24T10:27:16.802+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_30 !
[2024-12-24T10:27:16.802+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_48 !
[2024-12-24T10:27:16.804+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_12 !
[2024-12-24T10:27:16.805+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_36 !
[2024-12-24T10:27:16.805+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_37 !
[2024-12-24T10:27:16.806+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_17 !
[2024-12-24T10:27:16.806+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_27 !
[2024-12-24T10:27:16.807+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_1 !
[2024-12-24T10:27:16.807+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_15 !
[2024-12-24T10:27:16.808+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_13 !
[2024-12-24T10:27:16.809+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_5 !
[2024-12-24T10:27:16.810+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_7 !
[2024-12-24T10:27:16.811+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_20 !
[2024-12-24T10:27:16.812+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_32 !
[2024-12-24T10:27:16.814+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_31 !
[2024-12-24T10:27:16.814+0000] {docker.py:73} INFO - 24/12/24 10:27:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_25_25 !
[2024-12-24T10:27:16.900+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2726 + 0) / 10000]
[2024-12-24T10:27:21.325+0000] {docker.py:73} INFO - [Stage 15:=============>                                     (2726 + 8) / 10000]
[2024-12-24T10:27:23.767+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2731.1 in stage 15.0 (TID 2855) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2731, message=
[2024-12-24T10:27:23.773+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2731
[2024-12-24T10:27:23.774+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.775+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.775+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.776+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.776+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.777+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.778+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.778+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.779+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.779+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.780+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.780+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.781+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.782+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.784+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.784+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.787+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.790+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.792+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.793+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.793+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.794+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.794+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.794+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.795+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.796+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.804+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.804+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.805+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.805+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.805+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.805+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.808+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.808+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.809+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.809+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.809+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.809+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.809+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.810+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.810+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2733.1 in stage 15.0 (TID 2852) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2733, message=
[2024-12-24T10:27:23.810+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2733
[2024-12-24T10:27:23.810+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.811+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.811+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.811+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.811+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.811+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.811+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.812+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.812+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.812+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.812+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.812+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.812+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.812+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.813+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.813+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.813+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.813+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.813+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.813+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.813+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.814+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.815+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.815+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.815+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.815+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.815+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.816+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.816+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.816+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.816+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.816+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.816+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2729.1 in stage 15.0 (TID 2858) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2729, message=
[2024-12-24T10:27:23.817+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2729
[2024-12-24T10:27:23.817+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.817+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.817+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.817+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.817+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.818+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.818+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.818+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.818+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.818+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.818+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.818+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.819+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.819+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.819+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.819+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.819+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.819+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.819+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.819+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.820+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.820+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.820+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.821+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.821+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.822+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.823+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.829+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.832+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.833+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.834+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.834+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.835+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.835+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.836+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.836+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.836+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.836+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.836+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.837+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.837+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2727.1 in stage 15.0 (TID 2851) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2727, message=
[2024-12-24T10:27:23.838+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2727
[2024-12-24T10:27:23.838+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.839+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.840+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.840+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.841+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.842+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.843+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.844+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.844+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.845+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.846+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.846+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.847+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.847+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.847+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.847+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.847+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.847+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.848+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.848+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.848+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.848+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.849+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.849+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.849+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.850+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.851+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.852+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.853+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.853+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.854+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.855+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.855+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.857+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.859+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.860+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.861+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.861+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.862+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.862+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.862+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2723.1 in stage 15.0 (TID 2856) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2723, message=
[2024-12-24T10:27:23.863+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2723
[2024-12-24T10:27:23.863+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.863+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.863+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.863+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.863+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.864+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.864+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.864+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.864+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.864+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.864+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.865+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.865+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.865+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.866+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.866+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.867+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.867+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.867+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.867+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.868+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.868+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.868+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.868+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.868+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.868+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.869+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.869+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.869+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.869+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.869+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.870+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.870+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.870+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.870+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.870+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.870+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.871+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.871+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.871+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.871+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2730.1 in stage 15.0 (TID 2853) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2730, message=
[2024-12-24T10:27:23.871+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2730
[2024-12-24T10:27:23.872+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.872+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.872+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.872+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.872+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.872+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.873+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.873+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.873+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.873+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.873+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.874+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.874+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.874+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.874+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.874+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.874+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.875+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.875+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.875+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.876+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.876+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.876+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.876+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.877+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.877+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.878+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.878+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.878+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.878+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.878+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.879+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.879+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.879+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.879+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.879+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.880+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.880+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.880+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.880+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.881+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2728.1 in stage 15.0 (TID 2854) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2728, message=
[2024-12-24T10:27:23.881+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2728
[2024-12-24T10:27:23.881+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.881+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.881+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.882+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.882+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.882+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.882+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.882+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.882+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.883+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.883+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.883+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.883+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.883+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.884+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.884+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.884+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.884+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.884+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.884+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.885+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.885+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.885+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.885+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.885+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.885+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.885+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.886+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.886+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.886+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.886+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.886+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.886+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.887+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.887+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.887+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.887+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.887+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.887+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.888+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.888+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2732.1 in stage 15.0 (TID 2857) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2732, message=
[2024-12-24T10:27:23.888+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2732
[2024-12-24T10:27:23.888+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.888+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.889+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.889+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.889+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.889+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.890+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.890+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.890+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.891+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.891+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.891+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.891+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.892+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.892+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.892+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.892+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.893+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.893+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.893+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.893+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.893+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.894+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.894+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.894+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.894+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.895+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.895+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.895+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.895+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.895+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.896+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.896+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.896+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.896+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.896+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.897+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.897+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.897+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.897+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.897+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 161.1 in stage 15.0 (TID 2862) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=161, message=
[2024-12-24T10:27:23.897+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 161
[2024-12-24T10:27:23.898+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.898+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.898+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.898+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.898+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.898+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.898+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.899+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.899+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.899+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.899+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.899+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.899+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.900+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.900+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.900+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.900+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.900+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.900+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.900+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.901+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.901+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.901+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.901+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.901+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.901+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.902+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.902+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.902+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.902+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.902+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.902+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.903+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.903+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.903+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.903+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.903+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.903+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.904+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.904+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.904+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 1309.1 in stage 15.0 (TID 2859) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=1309, message=
[2024-12-24T10:27:23.904+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 1309
[2024-12-24T10:27:23.904+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.905+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.905+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.905+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.905+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.905+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.905+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.906+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.906+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.906+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.906+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.906+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.906+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.907+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.907+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.907+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.907+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.907+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.907+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.907+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.908+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.908+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.908+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.908+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.908+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.909+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.909+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.909+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.909+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.909+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.909+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.909+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.910+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.910+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.910+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.910+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.910+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.910+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.910+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.911+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.911+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2054.1 in stage 15.0 (TID 2863) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2054, message=
[2024-12-24T10:27:23.911+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2054
[2024-12-24T10:27:23.911+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.911+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.912+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.912+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.912+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.912+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.912+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.912+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.912+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.913+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.913+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.913+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.913+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.913+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.914+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.915+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.915+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.916+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.917+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.917+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.918+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.918+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.919+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.920+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.920+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.920+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.920+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.920+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.921+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.921+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.921+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.921+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.921+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.921+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.921+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.922+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.922+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.922+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.922+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.922+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.922+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 1650.1 in stage 15.0 (TID 2860) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=1650, message=
[2024-12-24T10:27:23.923+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 1650
[2024-12-24T10:27:23.923+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.923+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.923+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.923+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.923+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.923+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.924+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.924+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.924+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.924+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.924+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.924+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.924+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.925+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.925+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.925+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.925+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.925+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.925+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.925+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.926+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.926+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.926+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.926+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.926+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.926+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.927+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.927+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.927+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.927+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.927+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.927+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.927+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.928+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.928+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.928+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.928+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.928+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.928+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.928+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.929+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 502.1 in stage 15.0 (TID 2865) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=502, message=
[2024-12-24T10:27:23.929+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 502
[2024-12-24T10:27:23.929+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.929+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.929+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.929+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.930+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.930+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.930+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.930+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.930+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.930+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.930+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.931+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.931+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.931+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.931+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.931+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.931+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.931+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.932+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.932+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.932+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.932+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.932+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.932+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.932+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.933+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.933+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.933+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.933+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.933+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.933+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.933+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.933+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.934+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.934+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.934+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.934+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.934+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.934+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.934+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.935+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 1300.1 in stage 15.0 (TID 2866) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=1300, message=
[2024-12-24T10:27:23.935+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 1300
[2024-12-24T10:27:23.935+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.935+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.935+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.935+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.936+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.936+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.936+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.936+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.936+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.936+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.937+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.937+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.937+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.937+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.937+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.937+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.937+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.938+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.938+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.938+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.938+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.938+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.938+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.938+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.939+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.939+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.939+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.939+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.939+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.939+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.940+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.940+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.940+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.940+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.940+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.940+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.941+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.941+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.941+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.941+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.941+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 2368.1 in stage 15.0 (TID 2861) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=2368, message=
[2024-12-24T10:27:23.942+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 2368
[2024-12-24T10:27:23.942+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.942+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.942+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.943+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.943+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.943+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.943+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.943+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.944+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.944+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.944+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.944+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.944+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.944+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.944+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.945+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.945+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.945+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.945+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.945+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.945+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.945+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.946+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.946+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.946+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.946+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.946+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.946+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.946+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.947+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.947+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.947+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.947+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.947+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.947+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.948+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.948+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.948+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.948+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.948+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:23.948+0000] {docker.py:73} INFO - 24/12/24 10:27:23 WARN TaskSetManager: Lost task 188.1 in stage 15.0 (TID 2864) (172.19.0.5 executor 1): FetchFailed(null, shuffleId=3, mapIndex=-1, mapId=-1, reduceId=188, message=
[2024-12-24T10:27:23.948+0000] {docker.py:73} INFO - org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3 partition 188
[2024-12-24T10:27:23.949+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1739)
[2024-12-24T10:27:23.949+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11(MapOutputTracker.scala:1686)
[2024-12-24T10:27:23.949+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$11$adapted(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.949+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach(Iterator.scala:943)
[2024-12-24T10:27:23.949+0000] {docker.py:73} INFO - 	at scala.collection.Iterator.foreach$(Iterator.scala:943)
[2024-12-24T10:27:23.949+0000] {docker.py:73} INFO - 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
[2024-12-24T10:27:23.949+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1685)
[2024-12-24T10:27:23.949+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1327)
[2024-12-24T10:27:23.950+0000] {docker.py:73} INFO - 	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1289)
[2024-12-24T10:27:23.950+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)
[2024-12-24T10:27:23.950+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)
[2024-12-24T10:27:23.950+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)
[2024-12-24T10:27:23.950+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)
[2024-12-24T10:27:23.950+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)
[2024-12-24T10:27:23.950+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
[2024-12-24T10:27:23.951+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
[2024-12-24T10:27:23.951+0000] {docker.py:73} INFO - 	at org.apache.spark.rdd.CoalescedRDD.$anonfun$compute$1(CoalescedRDD.scala:99)
[2024-12-24T10:27:23.951+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)
[2024-12-24T10:27:23.951+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)
[2024-12-24T10:27:23.951+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.951+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
[2024-12-24T10:27:23.951+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.952+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.952+0000] {docker.py:73} INFO - 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
[2024-12-24T10:27:23.952+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:179)
[2024-12-24T10:27:23.952+0000] {docker.py:73} INFO - 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
[2024-12-24T10:27:23.952+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)
[2024-12-24T10:27:23.952+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)
[2024-12-24T10:27:23.953+0000] {docker.py:73} INFO - 	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
[2024-12-24T10:27:23.953+0000] {docker.py:73} INFO - 	at org.apache.spark.scheduler.Task.run(Task.scala:141)
[2024-12-24T10:27:23.953+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
[2024-12-24T10:27:23.953+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
[2024-12-24T10:27:23.953+0000] {docker.py:73} INFO - 	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
[2024-12-24T10:27:23.953+0000] {docker.py:73} INFO - 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
[2024-12-24T10:27:23.954+0000] {docker.py:73} INFO - 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
[2024-12-24T10:27:23.954+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
[2024-12-24T10:27:23.954+0000] {docker.py:73} INFO - 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
[2024-12-24T10:27:23.954+0000] {docker.py:73} INFO - 	at java.base/java.lang.Thread.run(Thread.java:840)
[2024-12-24T10:27:23.954+0000] {docker.py:73} INFO - 
[2024-12-24T10:27:23.954+0000] {docker.py:73} INFO - )
[2024-12-24T10:27:25.152+0000] {docker.py:73} INFO - [Stage 15:>                                                    (25 + 8) / 10000]
[2024-12-24T10:27:25.347+0000] {docker.py:73} INFO - [Stage 15:>                                                    (37 + 8) / 10000]
[2024-12-24T10:27:25.553+0000] {docker.py:73} INFO - [Stage 15:>                                                    (50 + 8) / 10000]
[2024-12-24T10:27:25.752+0000] {docker.py:73} INFO - [Stage 15:>                                                    (68 + 9) / 10000]
[2024-12-24T10:27:25.952+0000] {docker.py:73} INFO - [Stage 15:>                                                    (99 + 8) / 10000]
[2024-12-24T10:27:26.156+0000] {docker.py:73} INFO - [Stage 15:>                                                   (126 + 8) / 10000]
[2024-12-24T10:27:26.350+0000] {docker.py:73} INFO - [Stage 15:>                                                   (159 + 8) / 10000]
[2024-12-24T10:27:26.554+0000] {docker.py:73} INFO - [Stage 15:=>                                                  (201 + 8) / 10000]
[2024-12-24T10:27:26.755+0000] {docker.py:73} INFO - [Stage 15:=>                                                  (244 + 8) / 10000]
[2024-12-24T10:27:26.955+0000] {docker.py:73} INFO - [Stage 15:=>                                                  (259 + 8) / 10000]
[2024-12-24T10:27:27.157+0000] {docker.py:73} INFO - [Stage 15:=>                                                  (296 + 8) / 10000]
[2024-12-24T10:27:27.365+0000] {docker.py:73} INFO - [Stage 15:=>                                                  (337 + 8) / 10000]
[2024-12-24T10:27:27.565+0000] {docker.py:73} INFO - [Stage 15:=>                                                  (367 + 8) / 10000]
[2024-12-24T10:27:27.773+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (395 + 8) / 10000]
[2024-12-24T10:27:27.969+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (437 + 8) / 10000]
[2024-12-24T10:27:28.175+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (467 + 8) / 10000]
[2024-12-24T10:27:28.379+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (483 + 9) / 10000]
[2024-12-24T10:27:28.590+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (494 + 8) / 10000]
[2024-12-24T10:27:28.786+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (503 + 8) / 10000]
[2024-12-24T10:27:29.017+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (512 + 8) / 10000]
[2024-12-24T10:27:29.189+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (532 + 8) / 10000]
[2024-12-24T10:27:29.401+0000] {docker.py:73} INFO - [Stage 15:==>                                                 (566 + 8) / 10000]
[2024-12-24T10:27:29.591+0000] {docker.py:73} INFO - [Stage 15:===>                                                (596 + 8) / 10000]
[2024-12-24T10:27:29.794+0000] {docker.py:73} INFO - [Stage 15:===>                                                (627 + 9) / 10000]
[2024-12-24T10:27:30.006+0000] {docker.py:73} INFO - [Stage 15:===>                                               (663 + 12) / 10000]
[2024-12-24T10:27:30.206+0000] {docker.py:73} INFO - [Stage 15:===>                                                (733 + 9) / 10000]
[2024-12-24T10:27:30.405+0000] {docker.py:73} INFO - [Stage 15:====>                                               (785 + 8) / 10000]
[2024-12-24T10:27:30.611+0000] {docker.py:73} INFO - [Stage 15:====>                                              (836 + 10) / 10000]
[2024-12-24T10:27:30.823+0000] {docker.py:73} INFO - [Stage 15:====>                                               (852 + 8) / 10000]
[2024-12-24T10:27:31.036+0000] {docker.py:73} INFO - [Stage 15:====>                                               (858 + 8) / 10000]
[2024-12-24T10:27:31.248+0000] {docker.py:73} INFO - [Stage 15:====>                                              (863 + 10) / 10000]
[2024-12-24T10:27:31.463+0000] {docker.py:73} INFO - [Stage 15:====>                                               (871 + 8) / 10000]
[2024-12-24T10:27:31.653+0000] {docker.py:73} INFO - [Stage 15:====>                                               (880 + 8) / 10000]
[2024-12-24T10:27:31.866+0000] {docker.py:73} INFO - [Stage 15:====>                                               (883 + 8) / 10000]
[2024-12-24T10:27:32.077+0000] {docker.py:73} INFO - [Stage 15:====>                                               (891 + 8) / 10000]
[2024-12-24T10:27:32.285+0000] {docker.py:73} INFO - [Stage 15:====>                                               (903 + 9) / 10000]
[2024-12-24T10:27:32.475+0000] {docker.py:73} INFO - [Stage 15:====>                                               (914 + 9) / 10000]
[2024-12-24T10:27:32.687+0000] {docker.py:73} INFO - [Stage 15:====>                                               (922 + 8) / 10000]
[2024-12-24T10:27:32.903+0000] {docker.py:73} INFO - [Stage 15:====>                                               (934 + 9) / 10000]
[2024-12-24T10:27:33.073+0000] {docker.py:73} INFO - [Stage 15:====>                                              (945 + 10) / 10000]
[2024-12-24T10:27:33.276+0000] {docker.py:73} INFO - [Stage 15:====>                                               (958 + 8) / 10000]
[2024-12-24T10:27:33.480+0000] {docker.py:73} INFO - [Stage 15:====>                                              (968 + 10) / 10000]
[2024-12-24T10:27:33.682+0000] {docker.py:73} INFO - [Stage 15:=====>                                              (982 + 9) / 10000]
[2024-12-24T10:27:33.889+0000] {docker.py:73} INFO - [Stage 15:=====>                                              (999 + 8) / 10000]
[2024-12-24T10:27:34.088+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1014 + 8) / 10000]
[2024-12-24T10:27:34.284+0000] {docker.py:73} INFO - [Stage 15:=====>                                            (1026 + 10) / 10000]
[2024-12-24T10:27:34.490+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1052 + 8) / 10000]
[2024-12-24T10:27:34.690+0000] {docker.py:73} INFO - [Stage 15:=====>                                            (1054 + 11) / 10000]
[2024-12-24T10:27:34.937+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1068 + 9) / 10000]
[2024-12-24T10:27:35.128+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1081 + 8) / 10000]
[2024-12-24T10:27:35.304+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1096 + 8) / 10000]
[2024-12-24T10:27:35.515+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1105 + 8) / 10000]
[2024-12-24T10:27:35.707+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1120 + 8) / 10000]
[2024-12-24T10:27:36.107+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1132 + 9) / 10000]
[2024-12-24T10:27:36.317+0000] {docker.py:73} INFO - [Stage 15:=====>                                             (1148 + 8) / 10000]
[2024-12-24T10:27:36.503+0000] {docker.py:73} INFO - [Stage 15:=====>                                            (1158 + 15) / 10000]
[2024-12-24T10:27:36.711+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1178 + 8) / 10000]
[2024-12-24T10:27:36.902+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1188 + 9) / 10000]
[2024-12-24T10:27:37.147+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1200 + 8) / 10000]
[2024-12-24T10:27:37.353+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1210 + 8) / 10000]
[2024-12-24T10:27:37.549+0000] {docker.py:73} INFO - [Stage 15:======>                                           (1218 + 10) / 10000]
[2024-12-24T10:27:37.763+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1230 + 8) / 10000]
[2024-12-24T10:27:37.963+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1239 + 8) / 10000]
[2024-12-24T10:27:38.175+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1246 + 9) / 10000]
[2024-12-24T10:27:38.556+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1247 + 8) / 10000]
[2024-12-24T10:27:39.048+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1255 + 8) / 10000]
[2024-12-24T10:27:39.530+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1263 + 8) / 10000]
[2024-12-24T10:27:39.681+0000] {docker.py:73} INFO - [Stage 15:======>                                           (1269 + 10) / 10000]
[2024-12-24T10:27:39.880+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1272 + 9) / 10000]
[2024-12-24T10:27:40.082+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1286 + 8) / 10000]
[2024-12-24T10:27:40.282+0000] {docker.py:73} INFO - [Stage 15:======>                                           (1302 + 10) / 10000]
[2024-12-24T10:27:40.488+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1314 + 8) / 10000]
[2024-12-24T10:27:40.754+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1319 + 8) / 10000]
[2024-12-24T10:27:40.898+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1329 + 8) / 10000]
[2024-12-24T10:27:41.105+0000] {docker.py:73} INFO - [Stage 15:======>                                           (1337 + 10) / 10000]
[2024-12-24T10:27:41.344+0000] {docker.py:73} INFO - [Stage 15:======>                                           (1346 + 11) / 10000]
[2024-12-24T10:27:41.527+0000] {docker.py:73} INFO - [Stage 15:======>                                            (1361 + 8) / 10000]
[2024-12-24T10:27:41.723+0000] {docker.py:73} INFO - [Stage 15:=======>                                           (1373 + 8) / 10000]
[2024-12-24T10:27:41.951+0000] {docker.py:73} INFO - [Stage 15:======>                                           (1374 + 12) / 10000]
[2024-12-24T10:27:42.139+0000] {docker.py:73} INFO - [Stage 15:=======>                                           (1381 + 8) / 10000]
[2024-12-24T10:27:42.349+0000] {docker.py:73} INFO - [Stage 15:=======>                                           (1389 + 8) / 10000]
[2024-12-24T10:27:42.544+0000] {docker.py:73} INFO - [Stage 15:=======>                                           (1399 + 8) / 10000]
[2024-12-24T10:27:42.740+0000] {docker.py:73} INFO - [Stage 15:=======>                                          (1421 + 10) / 10000]
[2024-12-24T10:27:42.966+0000] {docker.py:73} INFO - [Stage 15:=======>                                           (1439 + 8) / 10000]
[2024-12-24T10:27:43.146+0000] {docker.py:73} INFO - [Stage 15:=======>                                           (1443 + 8) / 10000]
[2024-12-24T10:27:43.386+0000] {docker.py:73} INFO - [Stage 15:=======>                                           (1458 + 8) / 10000]
[2024-12-24T10:27:43.443+0000] {local_task_job_runner.py:346} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2024-12-24T10:27:43.460+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2024-12-24T10:27:43.474+0000] {process_utils.py:132} INFO - Sending 15 to group 997. PIDs of all processes in the group: [997]
[2024-12-24T10:27:43.476+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 997
[2024-12-24T10:27:43.477+0000] {taskinstance.py:3093} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-12-24T10:27:43.482+0000] {docker.py:539} INFO - Stopping docker container
[2024-12-24T10:27:45.616+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-24T10:27:45.713+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=997, status='terminated', exitcode=0, started='10:26:14') (997) terminated with exit code 0
