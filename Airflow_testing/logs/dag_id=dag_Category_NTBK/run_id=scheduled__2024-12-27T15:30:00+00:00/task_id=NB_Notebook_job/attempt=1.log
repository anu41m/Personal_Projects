[2025-01-05T13:52:54.226+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-05T13:52:54.452+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_Category_NTBK.NB_Notebook_job scheduled__2024-12-27T15:30:00+00:00 [queued]>
[2025-01-05T13:52:54.573+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_Category_NTBK.NB_Notebook_job scheduled__2024-12-27T15:30:00+00:00 [queued]>
[2025-01-05T13:52:54.576+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-01-05T13:52:54.856+0000] {taskinstance.py:2889} INFO - Executing <Task(DockerOperator): NB_Notebook_job> on 2024-12-27 15:30:00+00:00
[2025-01-05T13:52:54.921+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=93) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-05T13:52:54.929+0000] {standard_task_runner.py:72} INFO - Started process 109 to run task
[2025-01-05T13:52:54.952+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'dag_Category_NTBK', 'NB_Notebook_job', 'scheduled__2024-12-27T15:30:00+00:00', '--job-id', '561', '--raw', '--subdir', 'DAGS_FOLDER/dag_category.py', '--cfg-path', '/tmp/tmpqbzu8hrl']
[2025-01-05T13:52:54.960+0000] {standard_task_runner.py:105} INFO - Job 561: Subtask NB_Notebook_job
[2025-01-05T13:52:55.562+0000] {task_command.py:467} INFO - Running <TaskInstance: dag_Category_NTBK.NB_Notebook_job scheduled__2024-12-27T15:30:00+00:00 [running]> on host 44275986e897
[2025-01-05T13:52:56.265+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Anoop M' AIRFLOW_CTX_DAG_ID='dag_Category_NTBK' AIRFLOW_CTX_TASK_ID='NB_Notebook_job' AIRFLOW_CTX_EXECUTION_DATE='2024-12-27T15:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-12-27T15:30:00+00:00'
[2025-01-05T13:52:56.286+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-05T13:52:58.391+0000] {docker.py:379} INFO - Starting docker container from image spark-cluster:version-1.0.0
[2025-01-05T13:53:06.780+0000] {docker.py:73} INFO - Input Notebook:  /home/jovyan/Notebooks/NB_DIM_Category.ipynb
[2025-01-05T13:53:06.799+0000] {docker.py:73} INFO - Output Notebook: /home/jovyan/Notebooks/output/NB_DIM_Category.ipynb
[2025-01-05T13:53:14.434+0000] {docker.py:73} INFO - Executing notebook with kernel: python3
[2025-01-05T13:53:14.454+0000] {docker.py:73} INFO - Executing Cell 1---------------------------------------
[2025-01-05T13:53:23.307+0000] {docker.py:73} INFO - Ending Cell 1------------------------------------------
[2025-01-05T13:53:23.329+0000] {docker.py:73} INFO - Executing Cell 2---------------------------------------
[2025-01-05T13:53:23.760+0000] {docker.py:73} INFO - Ending Cell 2------------------------------------------
[2025-01-05T13:53:23.794+0000] {docker.py:73} INFO - Executing Cell 3---------------------------------------
[2025-01-05T13:54:00.368+0000] {docker.py:73} INFO - :: loading settings :: url = jar:file:/usr/local/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-01-05T13:54:04.271+0000] {docker.py:73} INFO - Ivy Default Cache set to: /home/jovyan/.ivy2/cache
[2025-01-05T13:54:04.314+0000] {docker.py:73} INFO - The jars for the packages stored in: /home/jovyan/.ivy2/jars
[2025-01-05T13:54:04.450+0000] {docker.py:73} INFO - io.delta#delta-spark_2.12 added as a dependency
[2025-01-05T13:54:04.721+0000] {docker.py:73} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-0271c427-d9be-45fb-a3a1-6d2e0e1c7504;1.0
[2025-01-05T13:54:04.768+0000] {docker.py:73} INFO - 	confs: [default]
[2025-01-05T13:54:33.494+0000] {docker.py:73} INFO - 	found io.delta#delta-spark_2.12;3.1.0 in central
[2025-01-05T13:54:38.228+0000] {docker.py:73} INFO - 	found io.delta#delta-storage;3.1.0 in central
[2025-01-05T13:54:49.088+0000] {docker.py:73} INFO - 	found org.antlr#antlr4-runtime;4.9.3 in central
[2025-01-05T13:54:49.688+0000] {docker.py:73} INFO - downloading https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.1.0/delta-spark_2.12-3.1.0.jar ...
[2025-01-05T13:57:30.900+0000] {local_task_job_runner.py:346} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2025-01-05T13:57:30.922+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-05T13:57:30.928+0000] {process_utils.py:132} INFO - Sending 15 to group 109. PIDs of all processes in the group: [109]
[2025-01-05T13:57:30.929+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 109
[2025-01-05T13:57:30.937+0000] {taskinstance.py:3093} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-01-05T13:57:30.958+0000] {docker.py:539} INFO - Stopping docker container
[2025-01-05T13:57:31.524+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-05T13:57:31.565+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=109, status='terminated', exitcode=0, started='13:52:54') (109) terminated with exit code 0
